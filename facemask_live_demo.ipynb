{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./models/facemask.pth' ##Please enter path to the trained model\n",
    "device='cpu'  ##Please enter device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNNs\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, height=218, width=178, dim_output=2):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.H=height\n",
    "        self.W=width\n",
    "        self.output=dim_output\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout= nn.Dropout(p=0.5) \n",
    "        self.bn1= nn.BatchNorm2d(32) \n",
    "        self.bn2= nn.BatchNorm2d(64)\n",
    "        self.bn3= nn.BatchNorm2d(128)\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d( 3,  32,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,  64,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        #fully connected\n",
    "        self.fc1 = nn.Linear(128*(self.H//8)*(self.W//8),128) \n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,self.output)\n",
    "        \n",
    "        #sequential\n",
    "        self.layer1=nn.Sequential(self.conv1, self.bn1, self.max_pool, self.activation)\n",
    "        self.layer2=nn.Sequential(self.conv2, self.bn2, self.max_pool, self.activation)\n",
    "        self.layer3=nn.Sequential(self.conv3, self.bn3, self.max_pool, self.activation)\n",
    "        self.layer4=nn.Sequential(self.fc1, self.activation, self.dropout)\n",
    "        self.layer5=nn.Sequential(self.fc2, self.activation, self.dropout)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        \n",
    "        out=self.layer3(self.layer2(self.layer1(img)))\n",
    "        \n",
    "        ###flattening\n",
    "        batch_size =img.shape[0]\n",
    "        out=out.view(batch_size, -1)\n",
    "        \n",
    "        out=self.fc3(self.layer5(self.layer4(out)))\n",
    "       \n",
    "        return out\n",
    "    \n",
    "model=Model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "model_load=torch.load(model_path ,map_location=torch.device(device))\n",
    "model.load_state_dict(model_load['final_model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Please enter path to face and eye xml files#############################\n",
    "face_path=os.path.dirname(cv2.__file__)+'/data/haarcascade_frontalface_default.xml'\n",
    "eye_path =os.path.dirname(cv2.__file__)+'/data/haarcascade_eye.xml'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(face_path)\n",
    "eye_cascade = cv2.CascadeClassifier(eye_path)\n",
    "\n",
    "threshold = 80\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (30, 30)\n",
    "mask_font_color = (0, 255, 0)  #green\n",
    "nomask_font_color = (0, 0, 255) #red\n",
    "noface_font_color=(250, 206, 135) #light blue\n",
    "thickness = 2\n",
    "font_scale = 1\n",
    "mask = \"Thank you for wearing a mask\"\n",
    "#nomask = \"Please wear a mask\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    (a , img) = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, bw) = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    faces_gray = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    faces_bw = face_cascade.detectMultiScale(bw, 1.1, 4)\n",
    "    eyes = eye_cascade.detectMultiScale(gray)\n",
    "    \n",
    "    if(len(faces_gray) == 0 and len(faces_bw) == 0 and len(eyes) == 0):\n",
    "        cv2.putText(img, \"No face found\", org, font, font_scale, noface_font_color, thickness, cv2.LINE_AA)\n",
    "    else:\n",
    "        if(len(faces_gray) == 0 and len(faces_bw) == 0 and len(eyes) != 0):\n",
    "            cv2.putText(img, mask, org, font, font_scale, mask_font_color, thickness, cv2.LINE_AA)\n",
    "        else:\n",
    "            for (x, y, w, h) in faces_gray:\n",
    "                \n",
    "               \n",
    "                face_img = img[y:y+h, x:x+w]\n",
    "                rerect_sized=cv2.resize(face_img,(218,178))\n",
    "                normalized=rerect_sized/255.0\n",
    "                reshaped=np.reshape(normalized,(3,218,178))\n",
    "                reshaped = np.vstack([reshaped])\n",
    "                to_tensor=torchvision.transforms.ToTensor()\n",
    "                t_reshaped=to_tensor(reshaped)\n",
    "                tensor_reshaped=t_reshaped.unsqueeze(1).permute(1,2,3,0)\n",
    "                result=model(tensor_reshaped.float())\n",
    "                label1=torch.argmax(result, dim=1)[0]\n",
    "                label=label1.detach().item()\n",
    "                \n",
    "                if label == 1:\n",
    "                    cv2.putText(img, mask, org, font, font_scale, mask_font_color, thickness, cv2.LINE_AA)\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(img, \"no mask\", (x, y-10), font, font_scale, nomask_font_color, thickness, cv2.LINE_AA)\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('LIVE',   img)\n",
    "    key = cv2.waitKey(10)\n",
    "    \n",
    "    if key == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

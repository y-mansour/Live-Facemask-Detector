# Live-Facemask-Detector

This repository contains the code for creating a live facemask detector. It is recommended to install Pytorch, Tensorflow, OpenCV and common python libraries such as numpy and matpotlib to run the notebooks with no problems. The notebook "facemask_train" was run on cuda (Linux) and the notebook "facemask_live_demo" on cpu (windows).

The notebook "facemask_train" trains a classifier to distinguish between "mask" and "no mask". The dataset can be downloaded from: https://www.kaggle.com/ruchi798/periocular-detection. To run the notebook, in the first cell, you need to enter the path to the dataset and choose the device depending on if you will run on cpu or gpu. After running the notebook, the trained model will be automatically saved in the directory "models", such that it can be used in the next step. The trained model is already included in the repository, which means you do not have to run this notebook and you can proceed directly to the next step.

The notebook "facemask_live_demo" uses the saved/trained model to turn on the webcam and start the live demo. In the first cell, enter the device and the path to the saved model. For running this notebook, OpenCV must be installed. The algorithm uses the xml scripts "eye" and "frontalface_default" which should be automatically downloaded when installing OpenCV. However if this is not the case, you can download them from the xml directory in this repository or from: https://github.com/opencv/opencv/tree/master/data/haarcascades. After downloading the xml files, enter their paths in the last cell in the variables "eye_path" and "face_path". To obtain best possible performance, make sure you are in a well lit area with no light rays directed in the camera. 